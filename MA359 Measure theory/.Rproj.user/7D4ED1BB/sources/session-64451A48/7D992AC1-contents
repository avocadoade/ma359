# Product Measures

In this section we look at taking two measure spaces $(E, \mathcal{E}, \mu)$ and $(F, \mathcal{F}, \nu)$ and defining a $\sigma$ algebra and a measure on the product space $E \times F$. This will give us another way of defining Lebesgue measure on $\mathbb{R}^d$. First we remind ourselves of the definition of Cartesian product.

::: {.definition name="Cartesian product"}

If $E$ and $F$ are spaces then the Cartesian product $E \times F$ is the space of twoples $(x,y)$ where $x \in E$ and $y \in F$.

:::

::: {.example}

$\mathbb{R} \times \mathbb{R} = \mathbb{R}^2$.

:::


Now we want to consider the product $\sigma$-algebra. 

::: {.definition}

The product $\sigma$-algebra $\mathcal{E} \times \mathcal{F}$ is a $\sigma$-algebra on $E \times F$ which is generated by the collection 

$$ \mathcal{A} = \{ A \times B \,:\, A \in \mathcal{E}, B \in \mathcal{F}\}. $$

That is to say $\mathcal{E} \times \mathcal{F} = \sigma(\mathcal{A}).$

:::


We now take some time to look at the projection maps $\pi_E$ and $\pi_F$. 

::: {.definition}

We define two maps $\pi_E: E \times F \rightarrow E$ and $\pi_F: E \times F \rightarrow F$ by

$$ \pi_E (x,y) = x, \quad \pi_F(x,y) = y. $$

:::


::: {.lemma}

The maps $\pi_E$ and $\pi_F$ are both measurable. Furthermore if $C \in \mathcal{E} \times \mathcal{F}$ then the following sets are measurable

$$ C_x = \{ y \in F \,:\, (x,y) \in C \} = \pi_F\left(\pi_E^{-1}(\{x\}) \cap C\right) \in \mathcal{F} , \quad C_y = \{ x \in E \,:\, (x,y) \in C\} = \pi_E \left( \pi_F^{-1}(\{y\}) \cap C \right). ] $$

Furthermore if $f: E \times F \rightarrow G$ is a measurable function then $f_x: F \rightarrow G$ defined by $f_x(y) = f(x,y)$ and $f_y: E \rightarrow G$ defined by $f_y(x) = f(x,y)$ are both measurable functions. 

:::

::: {.proof}

First let us show that the projection maps are measurable. Let $A$ be in $\mathcal{E}$ then $\pi_E^{-1}(A) = A \times F$, as $F \in \mathcal{F}$ this is a product set so is in $\mathcal{E} \times \mathcal{F}$.

Now let us look at $C_x$. Let $\mathcal{C}$ be the collection of sets in $\mathcal{E} \times \mathcal{F}$ such that $C_x \in \mathcal{F}$. Then $\mathcal{C}$ contains all the product sets. We now want to show that $\mathcal{C}$ is a $\sigma$-algebra. $(C^c)_x = \{ y \in F \,:\, (x,y) \in C^c\} = \{ y \in F \, :\, (x,y) \notin C\}  = F \setminus \{ y \in F\,:\, (x,y) \in C\} = (C_x)^c$. Therefore $C \in \mathcal{C}$ implies that $C^c \in \mathcal{C}$. We also have that $\left(\bigcup_n C_n \right)_x = \bigcup_n \left( (C_n)_x \right)$. Therefore, $\mathcal{C}$ is closed under complements and countable unions so is a $\sigma$-algebra. Therefore $\mathcal{C} \supset \mathcal{E} \times \mathcal{F}$.

Now we move onto $f_x$. If $A \in \mathcal{F}$ then $f_x^{-1}(A) = \{ y \in F \,:\, f(x,y) \in A\} = (f^{-1}(A))_x$. Using the previous part we know that this is a measurable set. Therefore $f_x$ is measurable.

:::


::: {.theorem name="Product Measure"}

Given two $\sigma$-finite measure spaces $(E, \mathcal{E}, \mu)$ and $(F, \mathcal{F}, \nu)$ there exists a unique measure, $\mu \times \nu$, on $\mathcal{E} \times \mathcal{F}$ such that $(\mu \times \nu)(A \times B) = \mu(A)\nu(B)$ when $A \in \mathcal{E}$ and $B \in \mathcal{F}$. Furthermore

$$ (\mu \times \nu)(C) = \int_E \nu( C_x) \mu(\mathrm{d}x) = \int_F \mu(C_y) \nu(\mathrm{d}y).$$

:::

::: {.proof}

Let us begin in the case where both measure spaces are finite.
As $\mathcal{A} = \{ A \times B \,:\, A \in \mathcal{E}, B \in \mathcal{F}\}$ is a $\pi$-system generating $\mathcal{E} \times \mathcal{F}$ we can use Carathéodory's extension theorem to prove the first part of this theorem. However we will work directly as defining this measure is straightforward and useful for understanding it.

First we check that $x \mapsto \nu(C_x)$ and $y \mapsto \mu(C_y)$ are both measurable functions so the integrals are well defined. Let us begin in the case that $\nu$ is a finite measure. Let $\mathcal{C}$ be the collection of sets for which the function $x \mapsto \nu(C_x)$ is $\mathcal{E}$ measurable. If $C = A \times B$ then $\nu(C_x) = \nu(B)1_{x \in A}$ which is measurable. Now we want to show that $\mathcal{C}$ is a $\sigma$-algebra. If $C^1 \subset C^2$ then $\nu((C^2 \setminus C^1)_x) = \nu(C^2_x) - \nu(C^1_x)$ so $C^2 \setminus C^1 \in \mathcal{C}$. Suppose that $C^n$ is an increasing sequence of sets in $\mathcal{C}$ then $\nu\left( \left(\bigcup_n C^n\right)_x\right) = \lim_n \nu \left( C^n_x\right)$ so $\bigcup_n C_n$ is in $\mathcal{C}$. Therefore $\mathcal{C}$ is a $\sigma$-algebra and consequently contains $\mathcal{E} \times \mathcal{F}$. Now the only reason that we needed $\nu$ to be finite was to ensure that $A \times B \in \mathcal{C}$ as otherwise this function might take the value infinity sometimes. You can solve this problem by putting a $\sigma$-algebra on $[0,\infty]$ or we can work in the $\sigma$-finite setting and let $\{D_n\}$ be a sequence of disjoint subsets with $\nu(D_n)< \infty$ whose union is the whole of $F$. By the argument above $x \mapsto \nu((C\cap D_n)_x)$ is always measurable (restricting the space to $D_n$) and $\nu(C_x) = \lim_n \sum_{k=1}^n \nu((C \cap D_n)_x)$.

Now we move onto the main part of the proof we can define two different candidates for $(\mu \times \nu)$ namely

$$ (\mu \times \nu)_1(C) = \int_E \nu(C_x) \mu(\mathrm{d}x), \quad (\mu \times \nu)_2(C) = \int_F \mu(C_y) \nu(\mathrm{d}y). $$

We can see that if $C$ is of the form $A \times B$ then

$$ (\mu \times \nu)_1(A \times B) = \int_E \nu(B)1_{x \in A} \mu(\mathrm{d}x) = \mu(A) \nu(B) = \int_F \mu(A)1_{y \in B} \nu(\mathrm{d}y) = (\mu \times \nu)_2 (A \times B). $$

Now we know that $(\mu \times \nu)_1$ and $(\mu \times \nu)_2$ agree on a $\pi$-system generating $\mathcal{E} \times \mathcal{F}$ so Dynkin's uniqueness of extension lemma says that they agree on all of $\mathcal{E} \times \mathcal{F}$. 

Now we need to extend to the $\sigma$-finite case. There are sequences $E_n$ and $F_n$ of sets such that $\mu(E_n)<\infty, \nu(F_n)< \infty$ for every $n$ and $E= \bigcup_n E_n, F = \bigcup_n F_n$. Then we know that $x \mapsto \nu((C \cap (E_n \times F_n))_x)$ is a measurable function of $x$ for every $n$, so letting $n$ tend to infinity we have $\nu(C_x) = \lim_n \nu((C \cap (E_n \times F_n))_x)$ so $x \mapsto \nu(C_x)$ is the limit of measurable functions so measurable. Therefore in the $\sigma$ finite case we can still define our two candidate measures $(\mu \times \nu)_1$ and $(\mu \times \nu)_2$ and we have that $(\mu \times \nu_1(C) = \lim_n (\mu \times \nu))_1(C \cap (E_n \times F_n)) = \lim_n (\mu \times \nu)_2 ( C \cap (E_n \times F_n)) = (\mu \times \nu)_2 (C)$. So the two measures are equal.

Now let $(\mu \times \nu)_3$ be any other candidate measure on $E \times F$ such that $(\mu \times \nu)_3 (A \times B) = \mu(A) \nu(B)$. Dynkin's uniqueness of extension theorem tells us that it must be equal to $(\mu \times \nu)$ when restricted to $E_n \times F_n$ for any $n$. We can then repeat exactly the same argument as above to extend it to any set in $\mathcal{E} \times \mathcal{F}$.

:::


One of the key tools we get when using product measure is Fubini's theorem. There are two theorems one for positive functions, one for integrable functions. The naming gets a bit wooly, but often the theorem for positive functions is called Tonelli's theorem and that for integrable functions is called Fubini's theorem. Sometimes the later is called the Fubini-Tonelli theorem and sometimes both are called Fubini-Tonelli or Fubini. To play it safe I'm going to call both Fubini-Tonelli Theorem.

::: {.theorem name="Fubini-Tonelli theorem for positive functions"}

Suppose that $(E, \mathcal{E}, \mu)$ and $(F, \mathcal{F}, \nu)$ are $\sigma$-finite measure spaces and $f$ is a non-negative $\mathcal{E} \times \mathcal{F}$ measurable function then the functions $x \mapsto \int_F f(x,y) \nu(\mathrm{d}y)$ and $y \mapsto \int_E f(x,y) \mu(\mathrm{d}x)$ are both measurable and

$$(\mu \times \nu)(f) = \int_E \left( \int_F f(x,y) \nu(\mathrm{d}y) \right) \nu(\mathrm{d}x) = \int_F \left( \int_E f(x,y) \mu(\mathrm{d}x) \right) \nu(\mathrm{d}y). $$

:::

::: {.proof}

We build up the proof gradually, beginning with the case where $f$ is the indicator function of a set $C \in \mathcal{E} \times \mathcal{F}$. In this case the measurability of the integrals in $x$ or $y$ and the form for $(\mu \times \nu)(f)$ are given by the construction of the product measure in the previous theorem. 

The linearity of the integral then imply that the Fubini-Tonelli theorem holds whenever $f$ is a non-negative simple function, we also can see that $\int f(x,y) \nu(\mathrm{d}y)$ will be measurable as the previous lemma shows that $\int 1_{C_x}(y) \nu(\mathrm{d}y)$ is measurable and this is the sum of functions of that form.. We then note that any non-negative measurable function $f$, can be approximated from below by non-negative simple functions. Let $f_n$ be a sequence of simple functions approximating $f$. Then 

$$ f_n = \sum_{k=1}^{N_n} c^n_k 1_{C^n_k}, $$

where $C^n_k \in \mathcal{E} \times \mathcal{F}$. Then we know that

$$ (\mu \times \nu)(f_n) = \int_E \left( \int_F c^n_k 1_{C^n_k}(x,y) \nu(\mathrm{d}y) \right) \mu(\mathrm{d}x) = \int_E \left( \int_F c^n 1_{(C^n_k)_x}(y) \nu(\mathrm{d}y) \right)\mu(\mathrm{d}x). $$

By monotone convergence as $n \rightarrow \infty$ the left hand side converges to $(\mu \times \nu)(f)$. We can also see that by monotone convergence

$$ \int_F c^n 1_{(C^n_k)_x}(y) \nu(\mathrm{d}y) \uparrow \int_F f(x,y) \nu(\mathrm{d}y). $$

We note that this shows that $\int_F f(x,y) \nu(\mathrm{d}y)$ is the limit of measurable functions. Consequently, we use monotone convergence again to get that the right hand side converges to

$$ \int_E \left( \int_F f(x,y) \nu(\mathrm{d}y) \right) \mu(\mathrm{d}x). $$

This gives the desired conclusion for positive $f$. 

:::


\begin{thm}[Fubini-Tonelli theorem for integrable functions]
Suppose that $(E, \mathcal{E}, \mu)$ and $(F, \mathcal{F}, \nu)$ are $\sigma$-finite measure spaces and $f$ is a $\mathcal{E} \times \mathcal{F}$ measurable function which is integrable with respect to $(\mu \times \nu)$ then the functions

$$ g(x) = \left\{ \begin{array}{ll} \int_F f(x,y) \nu(\mathrm{d}y) & \int_F|f(x,y)| \nu(\mathrm{d}y) < \infty \\
0 & \int_F |f(x,y)| \nu(\mathrm{d}y) = \infty  \end{array} \right. $$

and 

$$ h(y) = \left\{ \begin{array}{ll} \int_E f(x,y) \mu(\mathrm{d}x) & \int_E |f(x,y)| \mu(\mathrm{d}x) < \infty \\
0 & \int_E |f(x,y)| \mu(\mathrm{d}x) = \infty \end{array} \right. $$

are both measurable and integrable. Furthermore,

$$ (\mu \times \nu)(f) = \int_E \left( \int_F f(x,y) \nu(\mathrm{d}y) \right) \nu(\mathrm{d}x) = \int_F \left( \int_E f(x,y) \mu(\mathrm{d}x) \right) \nu(\mathrm{d}y). $$

:::

::: {.proof}

Now we turn to the case where $f$ is not necessarily non-negative but is $(\mu \times \nu)$ integrable. By our result for non-negative functions we know that

$$ (\mu \times \nu)(|f|) = \int_E \left( \int_F |f(x,y)| \nu(\mathrm{d}y) \right) \mu(\mathrm{d}x), $$

which proves that the function $x \mapsto \int_F |f(x,y)| \nu(\mathrm{d}y)$ is $\mu$-integrable, and is consequently finite almost everywhere, therefore restricting the functions $g,h$ to where they would be finite is not a problem. Let $A$ be the set on which $x \mapsto \int_F |f(x,y)| \nu(\mathrm{d}y)$ is finite. Now we write $f = f_+ - f_-$ in our usual way. Then by definition

$$ \int f(x,y) \nu(\mathrm{d}y)1_{x \in A} =\left( \int f_+(x,y) \nu(\mathrm{d}y) - \int f_-(x,y) \nu(\mathrm{d}y)\right)1_{x \in A}.  $$

Then using the fact that $\mu(A^c)=0$, and our result for non-negative functions we have

\begin{align*} (\mu \times \nu)(f) = (\mu \times  \nu)(f_+) - (\mu \times \nu)(f_-) &= \int_E \int_F f_+(x,y) \nu(\mathrm{d}y)\mu(\mathrm{d}x) - \int_E \int_F f_-(x,y) \nu(\mathrm{d}y) \mu(\mathrm{d}x) \\
&= \int_E \left( \int_F f_+(x,y) \nu(\mathrm{d}y) - \int_F f_-(x,y) \nu(\mathrm{d}y) \right)1_{x \in A} \mu(\mathrm{d}x) \\
&= \int_E \left( \int_F f(x,y) \nu(\mathrm{d}y) 1_A\right) \mu(\mathrm{d}x)\\
&= \int_E \int_F f(x,y) \nu(\mathrm{d}y) \mu(\mathrm{d}x).
\end{align*}

:::


## Applications of product measure and Fubini's theorem

This section is a collection of examples and applications of product measure and Fubini's theorem

::: {.example}

Suppose $(E, \mathcal{E}, \mu)$ is a measure space we look at its product with $(\mathbb{R}, \mathcal{B}(\mathbb{R}), \lambda)$ and suppose that $f:E \rightarrow \mathbb{R}$ is a non-negative measurable, then the set

$$ A = \{(x,y) \,:\, 0 \leq y \leq f(x) \} $$

is measurable with the product $\sigma$-algebra and its measure is the *area under the graph* of $f$. We have that 

$$ (\mu \times \lambda)(A) = \mu( \lambda(A_x)) = \mu(f),  $$

and

$$ (\mu \times \lambda)(A) = \lambda( \mu(A_y)) = \lambda (\{ x \,:\, f(x) \geq y \}) = \int_0^ \infty \mu(\{x \,:\, f(x) \geq y\}) \mathrm{d}y. $$

:::




::: {.example name="Convolutions"}

Suppose that both $f$ and $g$ are in $L^1(\mathbb{R})$ then for almost every $x$ the function $ t \mapsto f(x-t) g(t)$ is also in $L^1(\mathbb{R})$. We have that the function $f*g$ defined by

$$ x \mapsto \left\{ \begin{array}{ll} \int_\mathbb{R} f(x-t)g(t) \mathrm{d}t & \mbox{if}\, t \mapsto f(x-t)g(t)\, \mbox{is Lebesgue integrable} \\
0 & \mbox{Otherwise} \end{array}\right. $$

is in $L^1$ and satisfies $\|f*g\|_1 \leq \|f\|_1 \|g\|_1$.

We can prove this using Fubini-Tonelli. First we want to check that $t \mapsto f(x-t)g(t)$ is measurable. Write $h(t) = x-t$ this continuous function (for fixed $x$) and $t \mapsto f(x-t) = f(h(t))$ so it is the composition of two measurable functions so measurable. We also know that the product of two measurable functions is measurable to $f(x-t)g(t)$ is a measurable function of $t$. Now we want to check that it is integrable

$$ \int \left| \int f(x-t)g(t) \mathrm{d}t \right| \mathrm{d}x \leq \int \int |f(x-t)g(t)| \mathrm{d}t \mathrm{d}x $$

as $f(x-t)g(t) \leq |f(x-t)g(t)|$ and $-f(x-t)g(t) \leq |f(x-t)g(t)|$. Now we apply Fubini-Tonelli and get

$$ \int \int |f(x-t)g(t)| \mathrm{d}t \mathrm{d}x = \int \left( \int |f(x-t)| \mathrm{d}x\right) |g(t)| \mathrm{d}t = \int \|f\|_1 |g(t)| \mathrm{d}t = \|f\|_1 \|g\|_1. $$

:::


We can also show that convolutions of functions are continuous functions using the tools from measure theory. For this we need to show that shifts are continuous in $L^1$.

::: {.lemma}

Define the map $T_\tau: L^p(\mathbb{R}) \rightarrow L^p(\mathbb{R})$ by $(T_\tau f)(x) = f(x+ \tau)$ then 

$$ \lim_{\tau \rightarrow 0}\|T_\tau f - f\|_p = 0. $$
:::

::: {.proof}

We want to show that for any $\epsilon$ there exists $\tau_*$ such that if $\tau \leq \tau_*$ then $\|T_\tau f-f\|_p \leq \epsilon$. First let us show the result for step functions, that is to say functions of the form

$$ \phi(x) = \sum_{k=1}^n a_k 1_{[c_k, d_k)}.$$

First by Minkowski's inequality we have

$$ \| T_\tau \phi - \phi\|_p \leq \sum_{k=1}^n |a_k| \| T_\tau 1_{[c_k, d_k)} - 1_{[c_k, d_k)}\|_p  = \sum_{k=1}^n |a_k| \lambda ([c_k + \tau, d_k + \tau) \Delta [c_k, d_k) \leq \sum_{k=1}^n |a_k| 2|\tau|.$$

Therefore we can make $\tau$ small enough so that this is less than $\epsilon$. 

Now let us look at a general $f$ we know (from Assignment 4) that there is a step function $\phi$ such that $\|f-\phi\|_p \leq \epsilon/3$. We also can change variables $x \leftrightarrow x+\tau$ so $\|T_\tau f - T_\tau \phi\|_p = \left( \int |f(x+\tau) - \phi(x+\tau)|^p \mathrm{d}x\right)^{1/p} = \|f-\phi\|_p$ for any $\tau$. For this $\phi$ we can find $\tau$ sufficiently small such that $\|T_\tau \phi - \phi\|_p \leq \epsilon/3$. Hence

$$ \|T_\tau f - f\|_p  \leq \|T_\tau f - T_\tau \phi\|_p + \| T_\tau \phi - \phi\|_p + \| \phi - f\|_p \leq \epsilon. $$

:::


Now we go back to convolutions, we can show that if $f,  \in L^p(\mathbb{R})$ and $g \in L^q(\mathbb{R})$ then $f*g$ is continous. 

$$ |f*g(y) - f*g(x)| = |\int_{\mathbb{R}}(f(x-t) - f(y-t)) g(t) \mathrm{d}t| \leq \int_\mathbb{R} |f(x-t)-f(y-t)||g(t)| \mathrm{d}t  $$

we can bound this using Hölder's inequailty by

$$ \|g\|_q \left(\int |f(x-t) - f(y-t)|^p\mathrm{d}t\right)^{1/p} = \|g\|_q \left(\int |f(t-x+y) - f(t)| \mathrm{d}t\right)^{1/p} = \|g\|_q \| T_{-x+y} f - f\|_p. $$

So if $|x-y|$ is small enough then $|f*g(x) - f*g(y)|$ will also be small.

