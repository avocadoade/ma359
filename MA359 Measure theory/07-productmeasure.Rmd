# Product Measures

In this section we look at taking two measure spaces $(E, \mathcal{E}, \mu)$ and $(F, \mathcal{F}, \nu)$ and defining a $\sigma$ algebra and a measure on the product space $E \times F$. This will give us another way of defining Lebesgue measure on $\mathbb{R}^d$. First we remind ourselves of the definition of Cartesian product.

::: {.definition name="Cartesian product"}

If $E$ and $F$ are spaces then the Cartesian product $E \times F$ is the space of twoples $(x,y)$ where $x \in E$ and $y \in F$.

:::

::: {.example}

$\mathbb{R} \times \mathbb{R} = \mathbb{R}^2$.

:::


Now we want to consider the product $\sigma$-algebra. 

::: {.definition}

The product $\sigma$-algebra $\mathcal{E} \times \mathcal{F}$ is a $\sigma$-algebra on $E \times F$ which is generated by the collection 

$$ \mathcal{A} = \{ A \times B \,:\, A \in \mathcal{E}, B \in \mathcal{F}\}. $$

That is to say $\mathcal{E} \times \mathcal{F} = \sigma(\mathcal{A}).$

:::


We now take some time to look at the projection maps $\pi_E$ and $\pi_F$. 

::: {.definition}

We define two maps $\pi_E: E \times F \rightarrow E$ and $\pi_F: E \times F \rightarrow F$ by

$$ \pi_E (x,y) = x, \quad \pi_F(x,y) = y. $$

:::


::: {.lemma}

The maps $\pi_E$ and $\pi_F$ are both measurable. Furthermore if $C \in \mathcal{E} \times \mathcal{F}$ then the following sets are measurable

$$ C_x = \{ y \in F \,:\, (x,y) \in C \} = \pi_F\left(\pi_E^{-1}(\{x\}) \cap C\right) \in \mathcal{F} , \quad C_y = \{ x \in E \,:\, (x,y) \in C\} = \pi_E \left( \pi_F^{-1}(\{y\}) \cap C \right). ] $$

Furthermore if $f: E \times F \rightarrow G$ is a measurable function then $f_x: F \rightarrow G$ defined by $f_x(y) = f(x,y)$ and $f_y: E \rightarrow G$ defined by $f_y(x) = f(x,y)$ are both measurable functions. 

:::

::: {.proof}

First let us show that the projection maps are measurable. Let $A$ be in $\mathcal{E}$ then $\pi_E^{-1}(A) = A \times F$, as $F \in \mathcal{F}$ this is a product set so is in $\mathcal{E} \times \mathcal{F}$.

Now let us look at $C_x$. Let $\mathcal{C}$ be the collection of sets in $\mathcal{E} \times \mathcal{F}$ such that $C_x \in \mathcal{F}$. Then $\mathcal{C}$ contains all the product sets. We now want to show that $\mathcal{C}$ is a $\sigma$-algebra. $(C^c)_x = \{ y \in F \,:\, (x,y) \in C^c\} = \{ y \in F \, :\, (x,y) \notin C\}  = F \setminus \{ y \in F\,:\, (x,y) \in C\} = (C_x)^c$. Therefore $C \in \mathcal{C}$ implies that $C^c \in \mathcal{C}$. We also have that $\left(\bigcup_n C_n \right)_x = \bigcup_n \left( (C_n)_x \right)$. Therefore, $\mathcal{C}$ is closed under complements and countable unions so is a $\sigma$-algebra. Therefore $\mathcal{C} \supset \mathcal{E} \times \mathcal{F}$.

Now we move onto $f_x$. If $A \in \mathcal{F}$ then $f_x^{-1}(A) = \{ y \in F \,:\, f(x,y) \in A\} = (f^{-1}(A))_x$. Using the previous part we know that this is a measurable set. Therefore $f_x$ is measurable.

:::


::: {.theorem name="Product Measure"}

Given two $\sigma$-finite measure spaces $(E, \mathcal{E}, \mu)$ and $(F, \mathcal{F}, \nu)$ there exists a unique measure, $\mu \times \nu$, on $\mathcal{E} \times \mathcal{F}$ such that $(\mu \times \nu)(A \times B) = \mu(A)\nu(B)$ when $A \in \mathcal{E}$ and $B \in \mathcal{F}$. Furthermore

$$ (\mu \times \nu)(C) = \int_E \nu( C_x) \mu(\mathrm{d}x) = \int_F \mu(C_y) \nu(\mathrm{d}y).$$

:::

::: {.proof}

Let us begin in the case where both measure spaces are finite.
As $\mathcal{A} = \{ A \times B \,:\, A \in \mathcal{E}, B \in \mathcal{F}\}$ is a $\pi$-system generating $\mathcal{E} \times \mathcal{F}$ we can use Carath√©odory's extension theorem to prove the first part of this theorem. However we will work directly as defining this measure is straightforward and useful for understanding it.

First we check that $x \mapsto \nu(C_x)$ and $y \mapsto \mu(C_y)$ are both measurable functions so the integrals are well defined. Let us begin in the case that $\nu$ is a finite measure. Let $\mathcal{C}$ be the collection of sets for which the function $x \mapsto \nu(C_x)$ is $\mathcal{E}$ measurable. If $C = A \times B$ then $\nu(C_x) = \nu(B)1_{x \in A}$ which is measurable. Now we want to show that $\mathcal{C}$ is a $\sigma$-algebra. If $C^1 \subset C^2$ then $\nu((C^2 \setminus C^1)_x) = \nu(C^2_x) - \nu(C^1_x)$ so $C^2 \setminus C^1 \in \mathcal{C}$. Suppose that $C^n$ is an increasing sequence of sets in $\mathcal{C}$ then $\nu\left( \left(\bigcup_n C^n\right)_x\right) = \lim_n \nu \left( C^n_x\right)$ so $\bigcup_n C_n$ is in $\mathcal{C}$. Therefore $\mathcal{C}$ is a $\sigma$-algebra and consequently contains $\mathcal{E} \times \mathcal{F}$. Now the only reason that we needed $\nu$ to be finite was to ensure that $A \times B \in \mathcal{C}$ as otherwise this function might take the value infinity sometimes. You can solve this problem by putting a $\sigma$-algebra on $[0,\infty]$ or we can work in the $\sigma$-finite setting and let $\{D_n\}$ be a sequence of disjoint subsets with $\nu(D_n)< \infty$ whose union is the whole of $F$. By the argument above $x \mapsto \nu((C\cap D_n)_x)$ is always measurable (restricting the space to $D_n$) and $\nu(C_x) = \lim_n \sum_{k=1}^n \nu((C \cap D_n)_x)$.

Now we move onto the main part of the proof we can define two different candidates for $(\mu \times \nu)$ namely

$$ (\mu \times \nu)_1(C) = \int_E \nu(C_x) \mu(\mathrm{d}x), \quad (\mu \times \nu)_2(C) = \int_F \mu(C_y) \nu(\mathrm{d}y). $$

We can see that if $C$ is of the form $A \times B$ then

$$ (\mu \times \nu)_1(A \times B) = \int_E \nu(B)1_{x \in A} \mu(\mathrm{d}x) = \mu(A) \nu(B) = \int_F \mu(A)1_{y \in B} \nu(\mathrm{d}y) = (\mu \times \nu)_2 (A \times B). $$

Now we know that $(\mu \times \nu)_1$ and $(\mu \times \nu)_2$ agree on a $\pi$-system generating $\mathcal{E} \times \mathcal{F}$ so Dynkin's uniqueness of extension lemma says that they agree on all of $\mathcal{E} \times \mathcal{F}$. 

Now we need to extend to the $\sigma$-finite case. There are sequences $E_n$ and $F_n$ of sets such that $\mu(E_n)<\infty, \nu(F_n)< \infty$ for every $n$ and $E= \bigcup_n E_n, F = \bigcup_n F_n$. Then we know that $x \mapsto \nu((C \cap (E_n \times F_n))_x)$ is a measurable function of $x$ for every $n$, so letting $n$ tend to infinity we have $\nu(C_x) = \lim_n \nu((C \cap (E_n \times F_n))_x)$ so $x \mapsto \nu(C_x)$ is the limit of measurable functions so measurable. Therefore in the $\sigma$ finite case we can still define our two candidate measures $(\mu \times \nu)_1$ and $(\mu \times \nu)_2$ and we have that $(\mu \times \nu_1(C) = \lim_n (\mu \times \nu))_1(C \cap (E_n \times F_n)) = \lim_n (\mu \times \nu)_2 ( C \cap (E_n \times F_n)) = (\mu \times \nu)_2 (C)$. So the two measures are equal.

Now let $(\mu \times \nu)_3$ be any other candidate measure on $E \times F$ such that $(\mu \times \nu)_3 (A \times B) = \mu(A) \nu(B)$. Dynkin's uniqueness of extension theorem tells us that it must be equal to $(\mu \times \nu)$ when restricted to $E_n \times F_n$ for any $n$. We can then repeat exactly the same argument as above to extend it to any set in $\mathcal{E} \times \mathcal{F}$.

:::


One of the key tools we get when using product measure is Fubini's theorem. There are two theorems one for positive functions, one for integrable functions. The naming gets a bit wooly, but often the theorem for positive functions is called Tonelli's theorem and that for integrable functions is called Fubini's theorem. Sometimes the later is called the Fubini-Tonelli theorem and sometimes both are called Fubini-Tonelli or Fubini. To play it safe I'm going to call both Fubini-Tonelli Theorem.

::: {.theorem name="Fubini-Tonelli theorem for positive functions"}

Suppose that $(E, \mathcal{E}, \mu)$ and $(F, \mathcal{F}, \nu)$ are $\sigma$-finite measure spaces and $f$ is a non-negative $\mathcal{E} \times \mathcal{F}$ measurable function then the functions $x \mapsto \int_F f(x,y) \nu(\mathrm{d}y)$ and $y \mapsto \int_E f(x,y) \mu(\mathrm{d}x)$ are both measurable and

$$(\mu \times \nu)(f) = \int_E \left( \int_F f(x,y) \nu(\mathrm{d}y) \right) \nu(\mathrm{d}x) = \int_F \left( \int_E f(x,y) \mu(\mathrm{d}x) \right) \nu(\mathrm{d}y). $$

:::

::: {.proof}

We build up the proof gradually, beginning with the case where $f$ is the indicator function of a set $C \in \mathcal{E} \times \mathcal{F}$. In this case the measurability of the integrals in $x$ or $y$ and the form for $(\mu \times \nu)(f)$ are given by the construction of the product measure in the previous theorem. 

The linearity of the integral then imply that the Fubini-Tonelli theorem holds whenever $f$ is a non-negative simple function, we also can see that $\int f(x,y) \nu(\mathrm{d}y)$ will be measurable as the previous lemma shows that $\int 1_{C_x}(y) \nu(\mathrm{d}y)$ is measurable and this is the sum of functions of that form.. We then note that any non-negative measurable function $f$, can be approximated from below by non-negative simple functions. Let $f_n$ be a sequence of simple functions approximating $f$. Then 

$$ f_n = \sum_{k=1}^{N_n} c^n_k 1_{C^n_k}, $$

where $C^n_k \in \mathcal{E} \times \mathcal{F}$. Then we know that

$$ (\mu \times \nu)(f_n) = \int_E \left( \int_F c^n_k 1_{C^n_k}(x,y) \nu(\mathrm{d}y) \right) \mu(\mathrm{d}x) = \int_E \left( \int_F c^n 1_{(C^n_k)_x}(y) \nu(\mathrm{d}y) \right)\mu(\mathrm{d}x). $$

By monotone convergence as $n \rightarrow \infty$ the left hand side converges to $(\mu \times \nu)(f)$. We can also see that by monotone convergence

$$ \int_F c^n 1_{(C^n_k)_x}(y) \nu(\mathrm{d}y) \uparrow \int_F f(x,y) \nu(\mathrm{d}y). $$

We note that this shows that $\int_F f(x,y) \nu(\mathrm{d}y)$ is the limit of measurable functions. Consequently, we use monotone convergence again to get that the right hand side converges to

$$ \int_E \left( \int_F f(x,y) \nu(\mathrm{d}y) \right) \mu(\mathrm{d}x). $$

This gives the desired conclusion for positive $f$. 

:::


\begin{thm}[Fubini-Tonelli theorem for integrable functions]
Suppose that $(E, \mathcal{E}, \mu)$ and $(F, \mathcal{F}, \nu)$ are $\sigma$-finite measure spaces and $f$ is a $\mathcal{E} \times \mathcal{F}$ measurable function which is integrable with respect to $(\mu \times \nu)$ then the functions

$$ g(x) = \left\{ \begin{array}{ll} \int_F f(x,y) \nu(\mathrm{d}y) & \int_F|f(x,y)| \nu(\mathrm{d}y) < \infty \\
0 & \int_F |f(x,y)| \nu(\mathrm{d}y) = \infty  \end{array} \right. $$

and 

$$ h(y) = \left\{ \begin{array}{ll} \int_E f(x,y) \mu(\mathrm{d}x) & \int_E |f(x,y)| \mu(\mathrm{d}x) < \infty \\
0 & \int_E |f(x,y)| \mu(\mathrm{d}x) = \infty \end{array} \right. $$

are both measurable and integrable. Furthermore,

$$ (\mu \times \nu)(f) = \int_E \left( \int_F f(x,y) \nu(\mathrm{d}y) \right) \nu(\mathrm{d}x) = \int_F \left( \int_E f(x,y) \mu(\mathrm{d}x) \right) \nu(\mathrm{d}y). $$

:::

::: {.proof}

Now we turn to the case where $f$ is not necessarily non-negative but is $(\mu \times \nu)$ integrable. By our result for non-negative functions we know that

$$ (\mu \times \nu)(|f|) = \int_E \left( \int_F |f(x,y)| \nu(\mathrm{d}y) \right) \mu(\mathrm{d}x), $$

which proves that the function $x \mapsto \int_F |f(x,y)| \nu(\mathrm{d}y)$ is $\mu$-integrable, and is consequently finite almost everywhere, therefore restricting the functions $g,h$ to where they would be finite is not a problem. Let $A$ be the set on which $x \mapsto \int_F |f(x,y)| \nu(\mathrm{d}y)$ is finite. Now we write $f = f_+ - f_-$ in our usual way. Then by definition

$$ \int f(x,y) \nu(\mathrm{d}y)1_{x \in A} =\left( \int f_+(x,y) \nu(\mathrm{d}y) - \int f_-(x,y) \nu(\mathrm{d}y)\right)1_{x \in A}.  $$

Then using the fact that $\mu(A^c)=0$, and our result for non-negative functions we have

\begin{align*} (\mu \times \nu)(f) = (\mu \times  \nu)(f_+) - (\mu \times \nu)(f_-) &= \int_E \int_F f_+(x,y) \nu(\mathrm{d}y)\mu(\mathrm{d}x) - \int_E \int_F f_-(x,y) \nu(\mathrm{d}y) \mu(\mathrm{d}x) \\
&= \int_E \left( \int_F f_+(x,y) \nu(\mathrm{d}y) - \int_F f_-(x,y) \nu(\mathrm{d}y) \right)1_{x \in A} \mu(\mathrm{d}x) \\
&= \int_E \left( \int_F f(x,y) \nu(\mathrm{d}y) 1_A\right) \mu(\mathrm{d}x)\\
&= \int_E \int_F f(x,y) \nu(\mathrm{d}y) \mu(\mathrm{d}x).
\end{align*}

:::


## Applications of product measure and Fubini's theorem

This section is a collection of examples and applications of product measure and Fubini's theorem

::: {.example}

Suppose $(E, \mathcal{E}, \mu)$ is a measure space we look at its product with $(\mathbb{R}, \mathcal{B}(\mathbb{R}), \lambda)$ and suppose that $f:E \rightarrow \mathbb{R}$ is a non-negative measurable, then the set

$$ A = \{(x,y) \,:\, 0 \leq y \leq f(x) \} $$

is measurable with the product $\sigma$-algebra and its measure is the *area under the graph* of $f$. We have that 

$$ (\mu \times \lambda)(A) = \mu( \lambda(A_x)) = \mu(f),  $$

and

$$ (\mu \times \lambda)(A) = \lambda( \mu(A_y)) = \lambda (\{ x \,:\, f(x) \geq y \}) = \int_0^ \infty \mu(\{x \,:\, f(x) \geq y\}) \mathrm{d}y. $$

:::




::: {.example name="Convolutions"}

Suppose that both $f$ and $g$ are in $L^1(\mathbb{R})$ then for almost every $x$ the function $ t \mapsto f(x-t) g(t)$ is also in $L^1(\mathbb{R})$. We have that the function $f*g$ defined by

$$ x \mapsto \left\{ \begin{array}{ll} \int_\mathbb{R} f(x-t)g(t) \mathrm{d}t & \mbox{if}\, t \mapsto f(x-t)g(t)\, \mbox{is Lebesgue integrable} \\
0 & \mbox{Otherwise} \end{array}\right. $$

is in $L^1$ and satisfies $\|f*g\|_1 \leq \|f\|_1 \|g\|_1$.

We can prove this using Fubini-Tonelli. First we want to check that $t \mapsto f(x-t)g(t)$ is measurable. Write $h(t) = x-t$ this continuous function (for fixed $x$) and $t \mapsto f(x-t) = f(h(t))$ so it is the composition of two measurable functions so measurable. We also know that the product of two measurable functions is measurable to $f(x-t)g(t)$ is a measurable function of $t$. Now we want to check that it is integrable

$$ \int \left| \int f(x-t)g(t) \mathrm{d}t \right| \mathrm{d}x \leq \int \int |f(x-t)g(t)| \mathrm{d}t \mathrm{d}x $$

as $f(x-t)g(t) \leq |f(x-t)g(t)|$ and $-f(x-t)g(t) \leq |f(x-t)g(t)|$. Now we apply Fubini-Tonelli and get

$$ \int \int |f(x-t)g(t)| \mathrm{d}t \mathrm{d}x = \int \left( \int |f(x-t)| \mathrm{d}x\right) |g(t)| \mathrm{d}t = \int \|f\|_1 |g(t)| \mathrm{d}t = \|f\|_1 \|g\|_1. $$

:::


We can also show that convolutions of functions are continuous functions using the tools from measure theory. For this we need to show that shifts are continuous in $L^1$.

::: {.lemma}

Define the map $T_\tau: L^p(\mathbb{R}) \rightarrow L^p(\mathbb{R})$ by $(T_\tau f)(x) = f(x+ \tau)$ then 

$$ \lim_{\tau \rightarrow 0}\|T_\tau f - f\|_p = 0. $$
:::

::: {.proof}

We want to show that for any $\epsilon$ there exists $\tau_*$ such that if $\tau \leq \tau_*$ then $\|T_\tau f-f\|_p \leq \epsilon$. First let us show the result for step functions, that is to say functions of the form

$$ \phi(x) = \sum_{k=1}^n a_k 1_{[c_k, d_k)}.$$

First by Minkowski's inequality we have

$$ \| T_\tau \phi - \phi\|_p \leq \sum_{k=1}^n |a_k| \| T_\tau 1_{[c_k, d_k)} - 1_{[c_k, d_k)}\|_p  = \sum_{k=1}^n |a_k| \lambda ([c_k + \tau, d_k + \tau) \Delta [c_k, d_k) \leq \sum_{k=1}^n |a_k| 2|\tau|.$$

Therefore we can make $\tau$ small enough so that this is less than $\epsilon$. 

Now let us look at a general $f$ we know (from Assignment 4) that there is a step function $\phi$ such that $\|f-\phi\|_p \leq \epsilon/3$. We also can change variables $x \leftrightarrow x+\tau$ so $\|T_\tau f - T_\tau \phi\|_p = \left( \int |f(x+\tau) - \phi(x+\tau)|^p \mathrm{d}x\right)^{1/p} = \|f-\phi\|_p$ for any $\tau$. For this $\phi$ we can find $\tau$ sufficiently small such that $\|T_\tau \phi - \phi\|_p \leq \epsilon/3$. Hence

$$ \|T_\tau f - f\|_p  \leq \|T_\tau f - T_\tau \phi\|_p + \| T_\tau \phi - \phi\|_p + \| \phi - f\|_p \leq \epsilon. $$

:::


Now we go back to convolutions, we can show that if $f,  \in L^p(\mathbb{R})$ and $g \in L^q(\mathbb{R})$ then $f*g$ is continous. 

$$ |f*g(y) - f*g(x)| = |\int_{\mathbb{R}}(f(x-t) - f(y-t)) g(t) \mathrm{d}t| \leq \int_\mathbb{R} |f(x-t)-f(y-t)||g(t)| \mathrm{d}t  $$

we can bound this using H√∂lder's inequailty by

$$ \|g\|_q \left(\int |f(x-t) - f(y-t)|^p\mathrm{d}t\right)^{1/p} = \|g\|_q \left(\int |f(t-x+y) - f(t)| \mathrm{d}t\right)^{1/p} = \|g\|_q \| T_{-x+y} f - f\|_p. $$

So if $|x-y|$ is small enough then $|f*g(x) - f*g(y)|$ will also be small.

